Sun Mar 19 03:10:24 EDT 2023
Slurm nodes: evc10
You were assigned 1 gpu(s)
Please run `conda env list` to see a list of all available environments. Use
`source activate <env>` to activate the environment '<env>'. 

Currently Loaded Modules:
  1) anaconda/anaconda3

 

	[4mGPU0	mlx5_0	CPU Affinity	NUMA Affinity[0m
GPU0	 X 	NODE	9,11	1
mlx5_0	NODE	 X 		

Legend:

  X    = Self
  SYS  = Connection traversing PCIe as well as the SMP interconnect between NUMA nodes (e.g., QPI/UPI)
  NODE = Connection traversing PCIe as well as the interconnect between PCIe Host Bridges within a NUMA node
  PHB  = Connection traversing PCIe as well as a PCIe Host Bridge (typically the CPU)
  PXB  = Connection traversing multiple PCIe bridges (without traversing the PCIe Host Bridge)
  PIX  = Connection traversing at most a single PCIe bridge
  NV#  = Connection traversing a bonded set of # NVLinks


1.13.1+cu116
11.6
Namespace(add_bn_next=True, add_bn_prev=False, arch='resnet18', checkpoint='checkpoint', class_order=[68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37, 95, 14, 71, 96, 98, 97, 2, 64, 66, 42, 22, 35, 86, 24, 34, 87, 21, 99, 0, 88, 27, 18, 94, 11, 12, 47, 25, 30, 46, 62, 69, 36, 61, 7, 63, 75, 5, 32, 4, 51, 48, 73, 93, 39, 67, 29, 49, 57, 33], compression=0.9, data_path='../../data/CIFAR', dataset='cifar100', display_gap=50, epochs=250, ft_epochs=250, ft_lr=0.1, ft_schedule=[100, 150, 200], ft_weight_decay=0.0005, gamma=0.1, growth_rate=0.1, increments=[10, 10, 10, 10, 10, 10, 10, 10, 10, 10], jobid='227652', logs='logs', lr=0.1, manual_seed=7137, momentum=0.9, overflow=False, pretrained_cps='./checkpoint/226429_resnet18/model0_best.pth', random_classes=False, resume=True, schedule=[100, 150, 200], starting_tid='0_ft', test_batch=100, train_batch=64, validation=0, weight_decay=0.0005, workers=4)
Files already downloaded and verified
Files already downloaded and verified
Class order: [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37, 95, 14, 71, 96, 98, 97, 2, 64, 66, 42, 22, 35, 86, 24, 34, 87, 21, 99, 0, 88, 27, 18, 94, 11, 12, 47, 25, 30, 46, 62, 69, 36, 61, 7, 63, 75, 5, 32, 4, 51, 48, 73, 93, 39, 67, 29, 49, 57, 33, [...]]
0
[10, 10, 10, 10, 10, 10, 10, 10, 10, 10]
1
[10, 10, 10, 10, 10, 10, 10, 10, 10, 10]
2
[10, 10, 10, 10, 10, 10, 10, 10, 10, 10]
3
[10, 10, 10, 10, 10, 10, 10, 10, 10, 10]
4
[10, 10, 10, 10, 10, 10, 10, 10, 10, 10]
5
[10, 10, 10, 10, 10, 10, 10, 10, 10, 10]
6
[10, 10, 10, 10, 10, 10, 10, 10, 10, 10]
7
[10, 10, 10, 10, 10, 10, 10, 10, 10, 10]
8
[10, 10, 10, 10, 10, 10, 10, 10, 10, 10]
9
[10, 10, 10, 10, 10, 10, 10, 10, 10, 10]
Resuming task: 0
[7, 13, 17, 11, 15, 25, 41, 14, 27, 37, 60, 93, 33, 82, 100, 160, 187, 70, 168, 60]


###########################################

Finetuning task 0

Task ID: [0] - Epoch: [1 | 250] LR: 0.100000

Keys:  ['time', 'acc1', 'acc5', 'ce_loss']
Training:  [0.08792431746857075, 66.53481012658227, 94.38291139240506, 1.0476273082526801]
Testing:  [0.0778501272201538, 60.2, 92.7, 1.2474728643894195]
Best Acc:  60.2

Task ID: [0] - Epoch: [51 | 250] LR: 0.100000

Keys:  ['time', 'acc1', 'acc5', 'ce_loss']
Training:  [0.03220269348047956, 88.17246835443038, 99.42642405063292, 0.35700032595969455]
Testing:  [0.0971536636352539, 78.8, 98.3, 0.7139316320419311]
Best Acc:  82.0
New lr for parameter group: 0  ->  0.010000000000000002

Task ID: [0] - Epoch: [101 | 250] LR: 0.010000

Keys:  ['time', 'acc1', 'acc5', 'ce_loss']
Training:  [0.03247648251207569, 93.19620253164557, 99.86155063291139, 0.21360574823014344]
Testing:  [0.07605879306793213, 89.7, 99.1, 0.34236865788698195]
Best Acc:  89.7
New lr for parameter group: 0  ->  0.0010000000000000002

Task ID: [0] - Epoch: [151 | 250] LR: 0.001000

Keys:  ['time', 'acc1', 'acc5', 'ce_loss']
Training:  [0.031746903552284725, 99.32753164556962, 100.0, 0.021483573022215992]
Testing:  [0.08432486057281494, 91.0, 99.5, 0.36090298295021056]
Best Acc:  91.3
New lr for parameter group: 0  ->  0.00010000000000000003

Task ID: [0] - Epoch: [201 | 250] LR: 0.000100

Keys:  ['time', 'acc1', 'acc5', 'ce_loss']
Training:  [0.029077200949946536, 99.86155063291139, 100.0, 0.00934876828112557]
Testing:  [0.09941620826721191, 91.1, 99.5, 0.3646211937069893]
Best Acc:  91.4
Running inference on model to measure class incremental accuracy ...
Total tasks: 1, CIL Acc: 91.80, Task-id Cls. Acc.:  100.00


__________________________________________________________________________________________

Training task:  1

Task ID: [1] - Epoch: [1 | 250] LR: 0.100000

Keys:  ['time', 'acc1', 'acc5', 'ce_loss']
Training:  [0.033955272239974785, 13.627373417721518, 56.764240506329116, 4.380502441261388]
Testing:  [0.08693516254425049, 15.4, 61.4, 2.386780619621277]
Best Acc:  15.4
slurmstepd: error: *** JOB 227652 ON evc10 CANCELLED AT 2023-03-19T03:28:29 ***
